TODO WEEK 5:

1. See if LSTM also has lower validation loss
2. Validate both transformers and LSTM with CRPS
3. See if you can train with other metrics like CRPS or KL Div
4. Figure out how to deal with empty values (0.0) for some of the columns
5. Implement early stopping
   <!-- 0. Read up all the divergence thing -->
   <!-- 1. Read up CRPS -->

6. use CRPS for validation, see if I can change the loss function to someting similar
<!-- 3. Use electric dataset  -->

<!-- 1. Try adding random noise as an independent feature to LSTM -->
<!-- 2. Implement train val test lines function -->
<!-- 3. Add random state and Try hyperparameter tuning X -->

6. Try differnet Informer and Autoformer X
<!-- 4. Try different prediction lengths  -->
7. Try different granularity
8. Try differetn patch sizes
<!-- 8. Find different datasets of multiple households -->

9. LSTM with all feature with refeeding
10. LSTM with Higher window size
    <!-- 3. Transfomer with no refeeding -->
    <!-- 11. Transformer with refeeding -->
11. Transformer with refeeding with all feature
12. Transformer with refeeding with higher or smaller window
13. Compute differences between the MSE for 1 step ahead, 2 step, 3 step ahead

14. Organize the functions

- Differences between MSE for refeeding and no refeeding
